{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For each dataset, and create a binary classification problem as follows. Assign to the positive class the class with the greatest number of examples, and assign to the netative class the rest of all the examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## 1st dataset: yXT_car\n",
    "data_car=pd.read_csv(\"yXT_car.csv\", header=None)\n",
    "data_car[0].value_counts()\n",
    "def transform(x):\n",
    "    return 1 if x==1 else -1\n",
    "data_car[0]=data_car[0].apply(transform)\n",
    "\n",
    "## 2nd dataset: yXT_seeds\n",
    "data_seeds=pd.read_csv(\"yXT_seeds.csv\", header=None)\n",
    "data_seeds[0].value_counts()\n",
    "def transform(x):\n",
    "    return 1 if x==1 else -1\n",
    "data_seeds[0]=data_seeds[0].apply(transform)\n",
    "\n",
    "## 3rd dataset: yXT_wine\n",
    "data_wine=pd.read_csv(\"yXT_wine.csv\", header=None)\n",
    "data_wine[0].value_counts()\n",
    "def transform(x):\n",
    "    return 1 if x==2 else -1\n",
    "data_wine[0]=data_wine[0].apply(transform)\n",
    "\n",
    "## 4th dataset: yXT_winequality\n",
    "data_winequality=pd.read_csv(\"yXT_winequality-white.csv\", header=None)\n",
    "data_winequality[0].value_counts()\n",
    "def transform(x):\n",
    "    return 1 if x==6 else -1\n",
    "data_winequality[0]=data_winequality[0].apply(transform)\n",
    "\n",
    "## 5th dataset: yXT_yeast   \n",
    "data_yeast=pd.read_csv(\"yXT_yeast.csv\", header=None)\n",
    "data_yeast[0].value_counts()\n",
    "def transform(x):\n",
    "    return 1 if x==3 else -1\n",
    "data_yeast[0]=data_yeast[0].apply(transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For each of five datasets, divide examples in each class to two groups with ratio 70%:30%. Importantly, for each class, the one group has 70% of examples and the other group has the rest of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## 1st dataset: yXT_car\n",
    "X_car_train, X_car_test, y_car_train, y_car_test=train_test_split(data_car.iloc[:,1::], data_car[0], \\\n",
    "                                                                  test_size=0.3, random_state=11)\n",
    "\n",
    "## 2nd dataset: yXT_seeds\n",
    "X_seeds_train, X_seeds_test, y_seeds_train, y_seeds_test=train_test_split(data_seeds.iloc[:,1::], data_seeds[0], \\\n",
    "                                                                  test_size=0.3, random_state=12)\n",
    "\n",
    "## 3rd dataset: yXT_wine\n",
    "X_wine_train, X_wine_test, y_wine_train, y_wine_test=train_test_split(data_wine.iloc[:,1::], data_wine[0], \\\n",
    "                                                                  test_size=0.3, random_state=13)\n",
    "\n",
    "## 4th dataset: yXT_winequality\n",
    "X_winequality_train, X_winequality_test, y_winequality_train, y_winequality_test=train_test_split(data_winequality.iloc[:,1::],\\\n",
    "                                                                            data_winequality[0],test_size=0.3, random_state=14)\n",
    "\n",
    "## 5th dataset: yXT_yeast   \n",
    "X_yeast_train, X_yeast_test, y_yeast_train, y_yeast_test=train_test_split(data_yeast.iloc[:,1::], data_yeast[0], \\\n",
    "                                                                  test_size=0.3, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Benchmark the pattern recognition performance on the testing subset using the linear SVM trained with the training subset, for each dataset. The regularization parameter $\\lambda$ is set to $1/n$ where $n$ is the number of training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8169556840077071\n",
      "0.746031746031746\n",
      "0.8888888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5557823129251701\n",
      "0.6995515695067265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "## 1st dataset: yXT_car\n",
    "clf=LinearSVC(C=1/len(y_car_train))\n",
    "clf.fit(X_car_train, y_car_train)\n",
    "print(clf.score(X_car_test, y_car_test))\n",
    "\n",
    "## 2nd dataset: yXT_seeds\n",
    "clf=LinearSVC(C=1/len(y_seeds_train))\n",
    "clf.fit(X_seeds_train, y_seeds_train)\n",
    "print(clf.score(X_seeds_test, y_seeds_test))\n",
    "\n",
    "## 3rd dataset: yXT_wine\n",
    "clf=LinearSVC(C=1/len(y_wine_train))\n",
    "clf.fit(X_wine_train, y_wine_train)\n",
    "print(clf.score(X_wine_test, y_wine_test))\n",
    "\n",
    "## 4th dataset: yXT_winequality\n",
    "clf=LinearSVC(C=1/len(y_winequality_train))\n",
    "clf.fit(X_winequality_train, y_winequality_train)\n",
    "print(clf.score(X_winequality_test, y_winequality_test))\n",
    "\n",
    "## 5th dataset: yXT_yeast   \n",
    "clf=LinearSVC(C=1/len(y_yeast_train))\n",
    "clf.fit(X_yeast_train, y_yeast_train)\n",
    "print(clf.score(X_yeast_test, y_yeast_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compare the above result with the dataset preprocessed by two types of normalization. \n",
    "  L1 normalization: L1-norm of each feature vector is one;\n",
    "  L2 normalization: L2-norm of each feature vector is one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_data_l1: 0.6994219653179191\n",
      "car_data_l2: 0.8169556840077071\n",
      "seeds_data_l1: 0.6507936507936508\n",
      "seeds_data_l2: 0.746031746031746\n",
      "wine_data_l1: 0.8518518518518519\n",
      "wine_data_l2: 0.5925925925925926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winequality_data_l1: 0.5510204081632653\n",
      "winequality_data_l2: 0.5591836734693878\n",
      "yeast_data_l1: 0.6995515695067265\n",
      "yeast_data_l2: 0.6995515695067265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "## 1st dataset: yXT_car\n",
    "for l in ['l1','l2']:\n",
    "    # intantiate a normalization transfomer:\n",
    "    transformer=Normalizer(norm=l).fit(data_car.iloc[:,1::]) \n",
    "    # tranform the data's features:\n",
    "    X_data=transformer.transform(data_car.iloc[:,1::]) \n",
    "    #split dataset used to train and test classifier:\n",
    "    X_car_train, X_car_test, y_car_train, y_car_test=train_test_split(X_data, data_car[0], \\\n",
    "                                                                  test_size=0.3)\n",
    "    # intantiate a svc classifier:\n",
    "    clf=LinearSVC(C=1/len(y_car_train))\n",
    "    # fit data to model:\n",
    "    clf.fit(X_car_train, y_car_train)\n",
    "    # print accuracy\n",
    "    print(clf_l1.score(X_car_test, y_car_test))\n",
    "\n",
    "## 2nd dataset: yXT_seeds\n",
    "for l in ['l1','l2']:\n",
    "    transformer=Normalizer(norm=l).fit(data_seeds.iloc[:,1::])\n",
    "    X_data=transformer.transform(data_seeds.iloc[:,1::])\n",
    "    X_seeds_train, X_seeds_test, y_seeds_train, y_seeds_test=train_test_split(X_data, data_seeds[0], \\\n",
    "                                                                  test_size=0.3)\n",
    "    clf=LinearSVC(C=1/len(y_seeds_train))\n",
    "    clf.fit(X_seeds_train, y_seeds_train)\n",
    "    print(clf_l1.score(X_seeds_test, y_seeds_test))\n",
    "\n",
    "## 3rd dataset: yXT_wine\n",
    "for l in ['l1','l2']:\n",
    "    transformer=Normalizer(norm=l).fit(data_wine.iloc[:,1::])\n",
    "    X_data=transformer.transform(data_wine.iloc[:,1::])\n",
    "    X_wine_train, X_wine_test, y_wine_train, y_wine_test=train_test_split(X_data, data_wine[0], \\\n",
    "                                                                  test_size=0.3)\n",
    "    clf=LinearSVC(C=1/len(y_wine_train))\n",
    "    clf.fit(X_wine_train, y_wine_train)\n",
    "    print(clf.score(X_wine_test, y_wine_test))\n",
    "    \n",
    "## 4th dataset: yXT_winequality\n",
    "for l in ['l1','l2']:\n",
    "    transformer=Normalizer(norm=l).fit(data_winequality.iloc[:,1::])\n",
    "    X_data=transformer.transform(data_winequality.iloc[:,1::])\n",
    "    X_winequality_train, X_winequality_test, y_winequality_train, y_winequality_test=train_test_split(X_data,\\\n",
    "                                                                            data_winequality[0],test_size=0.3)\n",
    "    clf=LinearSVC(C=1/len(y_winequality_train))\n",
    "    clf.fit(X_winequality_train, y_winequality_train)\n",
    "    print(clf.score(X_winequality_test, y_winequality_test))\n",
    "\n",
    "## 5th dataset: yXT_yeast   \n",
    "for l in ['l1','l2']:\n",
    "    transformer=Normalizer(norm=l).fit(data_yeast.iloc[:,1::])\n",
    "    X_data=transformer.transform(data_yeast.iloc[:,1::])\n",
    "    X_yeast_train, X_yeast_test, y_yeast_train, y_yeast_test=train_test_split(X_data, data_yeast[0], \\\n",
    "                                                                  test_size=0.3)\n",
    "    clf=LinearSVC(C=1/len(y_yeast_train))\n",
    "    clf.fit(X_yeast_train, y_yeast_train)\n",
    "    print(clf.score(X_yeast_test, y_yeast_test))\n",
    "    print(X_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Put each of five datasets back to multi-category classification problem. Train linear SVMs in the one-vs-rest manner with $\\lambda=1/n$. Benchmark the accuracies of three normalization methods: no normalization, L1 normalization, and L2 normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7186897880539499\n",
      "0.6994219653179191\n",
      "Normalizer(copy=True, norm='l1')\n",
      "0.6994219653179191\n",
      "Normalizer(copy=True, norm='l2')\n",
      "0.873015873015873\n",
      "0.4126984126984127\n",
      "Normalizer(copy=True, norm='l1')\n",
      "0.5238095238095238\n",
      "Normalizer(copy=True, norm='l2')\n",
      "0.9259259259259259\n",
      "0.3888888888888889\n",
      "Normalizer(copy=True, norm='l1')\n",
      "0.3888888888888889\n",
      "Normalizer(copy=True, norm='l2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46258503401360546\n",
      "0.4421768707482993\n",
      "Normalizer(copy=True, norm='l1')\n",
      "0.45782312925170066\n",
      "Normalizer(copy=True, norm='l2')\n",
      "0.33856502242152464\n",
      "0.32062780269058294\n",
      "Normalizer(copy=True, norm='l1')\n",
      "0.3183856502242152\n",
      "Normalizer(copy=True, norm='l2')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "## 1st dataset: yXT_car\n",
    "# benchmark the accuracies of data without normalizaiton\n",
    "data_car=pd.read_csv(\"yXT_car.csv\", header=None)\n",
    "X_car_train, X_car_test, y_car_train, y_car_test=train_test_split(data_car.iloc[:,1::], data_car[0], \\\n",
    "                                                                  test_size=0.3)\n",
    "clf=OneVsRestClassifier(LinearSVC(C=1/len(y_car_train))).fit(X_car_train,y_car_train)\n",
    "print(clf.score(X_car_test, y_car_test))\n",
    "# benchmarck the accuracies of data with the normaliztion respectively:L1 and L2.\n",
    "for l in ['l1','l2']:\n",
    "    transformer=Normalizer(norm=l).fit(data_car.iloc[:,1::])\n",
    "    X_data=transformer.transform(data_car.iloc[:,1::])\n",
    "    X_car_train, X_car_test, y_car_train, y_car_test=train_test_split(X_data, data_car[0], \\\n",
    "                                                                  test_size=0.3, random_state=11)\n",
    "    clf=OneVsRestClassifier(LinearSVC(C=1/len(y_car_train))).fit(X_car_train, y_car_train)\n",
    "    print(clf.score(X_car_test, y_car_test))\n",
    "    print(transformer)\n",
    "\n",
    "    \n",
    "## 2nd dataset: yXT_seeds\n",
    "# benchmark the accuracies of data without normalizaiton   \n",
    "data_seeds=pd.read_csv(\"yXT_seeds.csv\", header=None)\n",
    "X_seeds_train, X_seeds_test, y_seeds_train, y_seeds_test=train_test_split(data_seeds.iloc[:,1::], data_seeds[0], \\\n",
    "                                                                  test_size=0.3)\n",
    "clf=OneVsRestClassifier(LinearSVC(C=1/len(y_seeds_train))).fit(X_seeds_train, y_seeds_train)\n",
    "print(clf.score(X_seeds_test, y_seeds_test))\n",
    "# benchmarck the accuracies of data with the normaliztion respectively:L1 and L2.\n",
    "for l in ['l1','l2']:\n",
    "    transformer=Normalizer(norm=l).fit(data_seeds.iloc[:,1::])\n",
    "    X_data=transformer.transform(data_seeds.iloc[:,1::])\n",
    "    X_seeds_train, X_seeds_test, y_seeds_train, y_seeds_test=train_test_split(X_data, data_seeds[0], \\\n",
    "                                                                  test_size=0.3, random_state=12)\n",
    "    clf=OneVsRestClassifier(LinearSVC(C=1/len(y_seeds_train))).fit(X_seeds_train, y_seeds_train)\n",
    "    print(clf.score(X_seeds_test, y_seeds_test))\n",
    "    print(transformer)\n",
    "\n",
    "    \n",
    "## 3rd dataset: yXT_wine\n",
    "# benchmark the accuracies of data without normalizaiton    \n",
    "data_wine=pd.read_csv(\"yXT_wine.csv\", header=None)\n",
    "X_wine_train, X_wine_test, y_wine_train, y_wine_test=train_test_split(data_wine.iloc[:,1::], data_wine[0], \\\n",
    "                                                                  test_size=0.3)\n",
    "clf=OneVsRestClassifier(LinearSVC(C=1/len(y_wine_train))).fit(X_wine_train, y_wine_train)\n",
    "print(clf.score(X_wine_test, y_wine_test))\n",
    "# benchmarck the accuracies of data with the normaliztion respectively:L1 and L2.\n",
    "for l in ['l1','l2']:\n",
    "    transformer=Normalizer(norm=l).fit(data_wine.iloc[:,1::])\n",
    "    X_data=transformer.transform(data_wine.iloc[:,1::])\n",
    "    X_wine_train, X_wine_test, y_wine_train, y_wine_test=train_test_split(X_data, data_wine[0], \\\n",
    "                                                                  test_size=0.3)\n",
    "    clf=OneVsRestClassifier(LinearSVC(C=1/len(y_wine_train))).fit(X_wine_train, y_wine_train)\n",
    "    print(clf.score(X_wine_test, y_wine_test))\n",
    "    print(transformer)\n",
    "\n",
    "    \n",
    "## 4th dataset: yXT_winequality-white\n",
    "# benchmark the accuracies of data without normalizaiton     \n",
    "data_winequality=pd.read_csv(\"yXT_winequality-white.csv\", header=None)\n",
    "X_winequality_train, X_winequality_test, y_winequality_train, y_winequality_test=train_test_split(data_winequality.iloc[:,1::],\\\n",
    "                                                                            data_winequality[0],test_size=0.3)\n",
    "clf=OneVsRestClassifier(LinearSVC(C=1/len(y_winequality_train))).fit(X_winequality_train, y_winequality_train)\n",
    "print(clf.score(X_winequality_test, y_winequality_test))\n",
    "# benchmarck the accuracies of data with the normaliztion respectively:L1 and L2.\n",
    "for l in ['l1','l2']:\n",
    "    transformer=Normalizer(norm=l).fit(data_winequality.iloc[:,1::])\n",
    "    X_data=transformer.transform(data_winequality.iloc[:,1::])\n",
    "    X_winequality_train, X_winequality_test, y_winequality_train, y_winequality_test=train_test_split(X_data,\\\n",
    "                                                                            data_winequality[0],test_size=0.3)\n",
    "    clf=OneVsRestClassifier(LinearSVC(C=1/len(y_winequality_train))).fit(X_winequality_train, y_winequality_train)\n",
    "    print(clf.score(X_winequality_test, y_winequality_test))\n",
    "    print(transformer)\n",
    "   \n",
    "\n",
    "## 5th dataset: yXT_yeast\n",
    "# benchmark the accuracies of data without normalizaiton     \n",
    "data_yeast=pd.read_csv(\"yXT_yeast.csv\", header=None)\n",
    "X_yeast_train, X_yeast_test, y_yeast_train, y_yeast_test=train_test_split(data_yeast.iloc[:,1::], data_yeast[0], \\\n",
    "                                                                  test_size=0.3)\n",
    "clf=OneVsRestClassifier(LinearSVC(C=1/len(y_yeast_train))).fit(X_yeast_train, y_yeast_train)\n",
    "print(clf.score(X_yeast_test, y_yeast_test))\n",
    "# benchmarck the accuracies of data with the normaliztion respectively:L1 and L2.\n",
    "for l in ['l1','l2']:\n",
    "    transformer=Normalizer(norm=l).fit(data_yeast.iloc[:,1::])\n",
    "    X_data=transformer.transform(data_yeast.iloc[:,1::])\n",
    "    X_yeast_train, X_yeast_test, y_yeast_train, y_yeast_test=train_test_split(X_data, data_yeast[0], \\\n",
    "                                                                  test_size=0.3)\n",
    "    clf=OneVsRestClassifier(LinearSVC(C=1/len(y_yeast_train))).fit(X_yeast_train, y_yeast_train)\n",
    "    print(clf.score(X_yeast_test, y_yeast_test))\n",
    "    print(transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Estimate the value of $\\lambda$ by five-fold cross validation with candidate values $\\lambda = 0.1/n, 1/n, 10/n$, and benchmark the accuracies of the three normalization methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7005795411679984, 0.7038921847673263, 0.7559960220842907]\n",
      "[[0.7005795411679984, 0.7005795411679984, 0.7005795411679984], [0.7005795411679984, 0.7005795411679984, 0.7005795411679984]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "## 1st dataset' cross validation (yXT_car);\n",
    "data_car=pd.read_csv(\"yXT_car.csv\", header=None)\n",
    "# benchmark the accuracies of non-normalization:\n",
    "X_car_train, X_car_test, y_car_train, y_car_test=train_test_split(data_car.iloc[:,1::], data_car[0], \\\n",
    "                                                                  test_size=0.3)\n",
    "C_s = [0.1/len(y_car_train), 1/len(y_car_train), 10/len(y_car_train)]\n",
    "svm=LinearSVC()\n",
    "scores_nonorm = list()\n",
    "for C in C_s:\n",
    "    svm.C = C\n",
    "    this_scores = cross_val_score(svm, X_car_train, y_car_train, n_jobs=1)\n",
    "    scores_nonorm.append(np.mean(this_scores))\n",
    "print(scores_nonorm)    \n",
    "#benchmark the accuracies of L1 and L2 normalization:\n",
    "scores_norm = list()\n",
    "for l in ['l1','l2']:\n",
    "    transformer=Normalizer(norm=l).fit(data_car.iloc[:,1::])\n",
    "    X_data=transformer.transform(data_car.iloc[:,1::])\n",
    "    X_car_train, X_car_test, y_car_train, y_car_test=train_test_split(X_data, data_car[0], \\\n",
    "                                                                  test_size=0.3, random_state=11)\n",
    "    C_s = [0.1/len(y_car_train), 1/len(y_car_train), 10/len(y_car_train)]\n",
    "    scores=list()\n",
    "    for C in C_s:\n",
    "        svm.C = C\n",
    "        this_scores = cross_val_score(svm, X_car_train, y_car_train, n_jobs=1)\n",
    "        scores.append(np.mean(this_scores))\n",
    "    scores_norm.append(scores) \n",
    "print(scores_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8710344827586207, 0.8981609195402299, 0.9319540229885058]\n",
      "[[0.35356321839080457, 0.35356321839080457, 0.5022988505747127], [0.3673563218390804, 0.3673563218390804, 0.5990804597701149]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "## 2nd dataset' cross validation (yXT_seeds);\n",
    "data_seeds=pd.read_csv(\"yXT_seeds.csv\", header=None)\n",
    "# benchmark the accuracies of non-normalization:\n",
    "X_seeds_train, X_seeds_test, y_seeds_train, y_seeds_test=train_test_split(data_seeds.iloc[:,1::], data_seeds[0], \\\n",
    "                                                                  test_size=0.3)\n",
    "C_s = [0.1/len(y_seeds_train), 1/len(y_seeds_train), 10/len(y_seeds_train)]\n",
    "svm=LinearSVC()\n",
    "scores_nonorm = list()\n",
    "for C in C_s:\n",
    "    svm.C = C\n",
    "    this_scores = cross_val_score(svm, X_seeds_train, y_seeds_train, n_jobs=1)\n",
    "    scores_nonorm.append(np.mean(this_scores))\n",
    "print(scores_nonorm)    \n",
    "#benchmark the accuracies of L1 and L2 normalization:\n",
    "scores_norm = list()\n",
    "for l in ['l1','l2']:\n",
    "    transformer=Normalizer(norm=l).fit(data_seeds.iloc[:,1::])\n",
    "    X_data=transformer.transform(data_seeds.iloc[:,1::])\n",
    "    X_seeds_train, X_seeds_test, y_seeds_train, y_seeds_test=train_test_split(X_data, data_seeds[0], \\\n",
    "                                                                  test_size=0.3)\n",
    "    C_s = [0.1/len(y_seeds_train), 1/len(y_seeds_train), 10/len(y_seeds_train)]\n",
    "    scores=[]\n",
    "    for C in C_s:\n",
    "        svm.C = C\n",
    "        this_scores = cross_val_score(svm, X_seeds_train, y_seeds_train, n_jobs=1)\n",
    "        scores.append(np.mean(this_scores))\n",
    "    scores_norm.append(scores) \n",
    "print(scores_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Repeat Step 8 ten times to compute ten accuracies for each normalization method. Find the best method. Use the one sample t-test to examine the statistical significance of the difference in accuracy between the best methd and other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import Normalizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9523809523809523\n",
      "0.9047619047619048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n",
      "0.9206349206349206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for i in range(4):\n",
    "    ## Benchmark non-normalization's accuracies and find best parameter\n",
    "    X_seeds_train, X_seeds_test, y_seeds_train, y_seeds_test=train_test_split(data_seeds.iloc[:,1::], data_seeds[0], \\\n",
    "                                                                  test_size=0.3)\n",
    "    n=len(y_seeds_train)\n",
    "    C_s = [0.1/n, 1/n, 10/n]\n",
    "    svm=LinearSVC()\n",
    "    scores_nonorm = list()\n",
    "    for C in C_s:\n",
    "        svm.C = C\n",
    "        this_scores = cross_val_score(svm, X_seeds_train, y_seeds_train, n_jobs=1)\n",
    "        scores_nonorm.append(np.mean(this_scores))   \n",
    "    #print(scores_nonorm)\n",
    "    # find the best para index from the scores list:\n",
    "    best_para_index=np.argmax(scores_nonorm) \n",
    "    #print(best_para_index)\n",
    "    # find the best para based on the best para index and add the corresponding value to best para list:\n",
    "    best_para_nonorm.append(C_s[best_para_index]) \n",
    "    #print(C_s[best_para_index])\n",
    "    svm.C = C_s[best_para_index]\n",
    "    svm.fit(X_seeds_test,y_seeds_test)\n",
    "    print(svm.score(X_seeds_test,y_seeds_test))\n",
    "\n",
    "## plot precision-recall curve\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "labels = []\n",
    "Y = label_binarize(data_seeds[0], classes=[1, 2, 3])\n",
    "X_seeds_train, X_seeds_test, y_seeds_train, y_seeds_test=train_test_split(data_seeds.iloc[:,1::], Y, \\\n",
    "                                                                          test_size=0.3)\n",
    "\n",
    "classifier = OneVsRestClassifier(LinearSVC(C=C_s[best_para_index],random_state=random_state))\n",
    "classifier.fit(X_seeds_test, y_seeds_test)\n",
    "y_score = classifier.decision_function(X_seeds_test)    \n",
    "\n",
    "for i in range(3):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_seeds_test[:, i],\n",
    "                                                        y_score[:, i])\n",
    "    average_precision[i] = average_precision_score(y_seeds_test[:, i], y_score[:, i])\n",
    "    plt.plot(recall[i],precision[i])\n",
    "#labels.append('Precision-recall for class {0} (area = {1:0.2f})'\n",
    "                     # ''.format(i+1, average_precision[i]))\n",
    "\n",
    "#plt.legend(labels, loc=(0, -.38), prop=dict(size=14))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.873015873015873, 0.8888888888888888, 0.8888888888888888, 0.873015873015873, 0.9523809523809523, 0.9365079365079365, 0.8571428571428571, 0.9523809523809523, 0.9682539682539683, 0.8571428571428571]\n",
      "[0.36507936507936506, 0.4126984126984127, 0.38095238095238093, 0.38095238095238093, 0.38095238095238093, 0.5555555555555556, 0.6349206349206349, 0.42857142857142855, 0.3492063492063492, 0.38095238095238093]\n",
      "[0.6825396825396826, 0.47619047619047616, 0.3968253968253968, 0.6666666666666666, 0.3968253968253968, 0.3968253968253968, 0.5396825396825397, 0.42857142857142855, 0.38095238095238093, 0.4126984126984127]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\zhaoyiming\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## non-normalization: \n",
    "data_seeds=pd.read_csv(\"yXT_seeds.csv\", header=None)\n",
    "best_para_nonorm=[]\n",
    "\n",
    "## l1 normalization dataset:\n",
    "transformer=Normalizer(norm='l1').fit(data_seeds.iloc[:,1::])\n",
    "X_data_l1=transformer.transform(data_seeds.iloc[:,1::])\n",
    "best_para_norm_l1=[]\n",
    "\n",
    "## l2 normalization dataset:\n",
    "transformer=Normalizer(norm='l2').fit(data_seeds.iloc[:,1::])\n",
    "X_data_l2=transformer.transform(data_seeds.iloc[:,1::])\n",
    "best_para_norm_l2=[]\n",
    "\n",
    "scores_non=[]\n",
    "scores_l1=[]\n",
    "scores_l2=[]\n",
    "\n",
    "for i in range(10):\n",
    "    ## Benchmark non-normalization's accuracies and find best parameter\n",
    "    X_seeds_train, X_seeds_test, y_seeds_train, y_seeds_test=train_test_split(data_seeds.iloc[:,1::], data_seeds[0], \\\n",
    "                                                                  test_size=0.3)\n",
    "    n=len(y_seeds_train)\n",
    "    C_s = [0.1/n, 1/n, 10/n]\n",
    "    svm=LinearSVC()\n",
    "    scores_nonorm = list()\n",
    "    for C in C_s:\n",
    "        svm.C = C\n",
    "        this_scores = cross_val_score(svm, X_seeds_train, y_seeds_train, n_jobs=1)\n",
    "        scores_nonorm.append(np.mean(this_scores))   \n",
    "    #print(scores_nonorm)\n",
    "    # find the best para index from the scores list:\n",
    "    best_para_index=np.argmax(scores_nonorm) \n",
    "    #print(best_para_index)\n",
    "    # find the best para based on the best para index and add the corresponding value to best para list:\n",
    "    best_para_nonorm.append(C_s[best_para_index]) \n",
    "    #print(C_s[best_para_index])\n",
    "    svm.C=C_s[best_para_index]\n",
    "    svm.fit(X_seeds_test, y_seeds_test)\n",
    "    scores_non.append(svm.score(X_seeds_test, y_seeds_test))\n",
    "    \n",
    "    ## Benchmark L1 normalization's accuracies and find best parameter\n",
    "    scores_norm_l1 = list() \n",
    "    X_seeds_train, X_seeds_test, y_seeds_train, y_seeds_test=train_test_split(X_data_l1, data_seeds[0], \\\n",
    "                                                                  test_size=0.3)\n",
    "    n=len(y_seeds_train)\n",
    "    C_s = [0.1/n, 1/n, 10/n]\n",
    "    for C in C_s:\n",
    "        svm.C = C\n",
    "        this_scores = cross_val_score(svm, X_seeds_train, y_seeds_train, n_jobs=1)\n",
    "        scores_norm_l1.append(np.mean(this_scores))\n",
    "    #print(scores_norm_l1)\n",
    "    best_para_index=np.argmax(scores_norm_l1)\n",
    "    best_para_norm_l1.append(C_s[best_para_index])\n",
    "    \n",
    "    svm.C=C_s[best_para_index]\n",
    "    svm.fit(X_seeds_test, y_seeds_test)\n",
    "    scores_l1.append(svm.score(X_seeds_test, y_seeds_test))\n",
    "    ## Benchmark L2 normalization's accuracies and find best parameter\n",
    "    scores_norm_l2 = list() \n",
    "    X_seeds_train, X_seeds_test, y_seeds_train, y_seeds_test=train_test_split(X_data_l2, data_seeds[0], \\\n",
    "                                                                  test_size=0.3)\n",
    "    n=len(y_seeds_train)\n",
    "    C_s = [0.1/n, 1/n, 10/n]\n",
    "    for C in C_s:\n",
    "        svm.C = C\n",
    "        this_scores = cross_val_score(svm, X_seeds_train, y_seeds_train, n_jobs=1)\n",
    "        scores_norm_l2.append(np.mean(this_scores))\n",
    "    #print(scores_norm_l2)\n",
    "    best_para_index=np.argmax(scores_norm_l2)\n",
    "    best_para_norm_l2.append(C_s[best_para_index])\n",
    "    svm.C=C_s[best_para_index]\n",
    "    svm.fit(X_seeds_test, y_seeds_test)\n",
    "    scores_l2.append(svm.score(X_seeds_test, y_seeds_test))\n",
    "#print(best_para_nonorm[np.argmax(np.bincount(best_para_nonorm))])\n",
    "#print(best_para_norm_l1[np.argmax(np.bincount(best_para_norm_l1))])\n",
    "#print(best_para_norm_l2[np.argmax(np.bincount(best_para_norm_l2))])\n",
    "print(scores_non)\n",
    "print(scores_l1)\n",
    "print(scores_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47777777777777786"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "$=0.905 $x$$^{(2)}$=0.427 $x$$^{(3)}$=0.478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$\\overline{x}$$^{(1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.050793650793650794"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "scores_non=np.array(scores_non)\n",
    "scores_l1=np.array(scores_l1)\n",
    "scores_l2=np.array(scores_l2)\n",
    "\n",
    "d_mean_non_l1=np.sum(scores_non-scores_l1)/10\n",
    "d_mean_non_l2=np.sum(scores_non-scores_l2)/10\n",
    "d_mean_l1_l2=np.sum(scores_l1-scores_l2)/10\n",
    "s_non_l1=np.sqrt((np.square(scores_non-scores_l1).sum()-d_mean_non_l1**2/10)/9)\n",
    "s_non_l2=np.sqrt((np.square(scores_non-scores_l2).sum()-d_mean_non_l2**2/10)/9)\n",
    "s_l1_l2=np.sqrt((np.square(scores_l1-scores_l2).sum()-d_mean_l1_l2**2/10)/9)\n",
    "t_non_l1=d_mean_non_l1/(s_non_l1/np.sqrt(10))\n",
    "t_non_l2=d_mean_non_l2/(s_non_l2/np.sqrt(10))\n",
    "t_l1_l2=d_mean_l1_l2/(s_l1_l2/np.sqrt(10))\n",
    "p_value_non_l1=stats.t.sf(abs(t_non_l1),9)\n",
    "p_value_non_l2=stats.t.sf(abs(t_non_l2),9)\n",
    "p_value_l1_l2=stats.t.sf(abs(t_l1_l2),9)\n",
    "d_mean_l1_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
